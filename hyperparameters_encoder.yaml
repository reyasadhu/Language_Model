batch_size: 16
block_size: 32
vocab_size: 2000
bias: True
dropout: 0
learning_rate: 5e-4
weight_decay: 0.00001
beta1: 0.7
beta2: 0.95
n_embd: 64
n_head: 2
n_layer: 4
eval_interval: 100
max_iters: 500
eval_iters: 200
n_input: 64
n_hidden: 100
n_output: 3
epochs_CLS: 15
mlp_expansion_ratio: 13
attention_mode: AliBi
mode: explore
eval_interval: 100
max_iters: 500 
eval_iters: 200
